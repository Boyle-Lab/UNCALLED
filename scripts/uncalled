#!/usr/bin/env python

# MIT License
#
# Copyright (c) 2018 Sam Kovaka <skovaka@gmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

from uncalled import mapping, index, pafstats, minknow_client
import numpy as np
import sys                         
import os
import argparse
import time
import re
import time
import subprocess
import traceback


MAX_SLEEP = 0.01

class ArgFormat(argparse.ArgumentDefaultsHelpFormatter):
    pass

def add_bwa_opt(p):
    p.add_argument("-x", "--bwa-prefix", required=True, type=str, help="BWA prefix to mapping to. Must be processed by \"uncalled index\".")
    p.add_argument("-p", "--preset-mode", default="default", type=str, help="Mapping mode")

def add_index_opts(p):
    p.add_argument("-i", "--ref-fasta", required=True, type=str, help="FASTA file used to build BWA index")
    p.add_argument("-s", "--max-sample-dist", default=100, type=int, help="Maximum average sampling distance between reference self-alignments.")
    p.add_argument("--min-samples", default=50000, type=int, help="Minimum number of self-alignments to produce (approximate, due to deterministically random start locations)")
    p.add_argument("-k", "--kmer-len", default=5, type=int, help="Model k-mer length")
    p.add_argument("-1", "--matchpr1", default=0.6334, type=float, help="Minimum event match probability")
    p.add_argument("-2", "--matchpr2", default=0.9838, type=float, help="Maximum event match probability")
    p.add_argument("-f", "--pathlen-percentile", default=0.05, type=float, help="")
    p.add_argument("-m", "--max-replen", default=100, type=int, help="")
    p.add_argument("--probs", default=None, type=str, help="Find parameters with specified target probabilites (comma separated)")
    p.add_argument("--speeds", default=None, type=str, help="Find parameters with specified speed coefficents (comma separated)")

def add_ru_opts(p):
    #TODO: selectively enrich or deplete refs in index
    p.add_argument("-D", "--deplete", required=False, action='store_true', default=False, help="Will eject reads that align to index")
    p.add_argument("-E", "--enrich", required=False, action='store_true', default=False, help="Will eject reads that don't align to index")
    p.add_argument("-c", "--max-chunks-proc", default=10, type=int, help="Will give up on a read after this many chunks have been processed. Only has effect when --unblock is set")
    p.add_argument("--full", action='store_true', help="Will monitor all pores if set (default)")
    p.add_argument("--even", action='store_true', help="Will only monitor even pores if set")
    p.add_argument("--odd", action='store_true', help="Will only monitor odd pores if set")
    p.add_argument("--chunk-size", required=False, type=float, default=1, help="Length of chunks in seconds")
    p.add_argument("--evt-buffer-len", default=6000, type=int, help="Size of buffer used to normalize and read events")
    p.add_argument("--evt-batch-size", default=5, type=int, help="Number of events simulator will mapping per read per thread iteration. Only has effect when --unblock is set")
    p.add_argument("--evt-timeout", default=10.0, type=float, help="Simulator will stop aligning event batch if average time in MS to mapping an event exceeds this. Only has effect when --unblock is set")
    p.add_argument("--max-chunk-wait", required=False, type=float, default=4000, help="Maximum milliseconds to wait between chunks. Will give up on read if it takes longer")
    p.add_argument("--scan-interval", required=False, type=float, default=5400, help="Approximate time between mux scans, in seconds")
    p.add_argument("--scan-extra", required=False, type=float, default=90, help="Wiggle room for predicting mux scans, in seconds")

def add_realtime_opts(p):
    p.add_argument('--host', default='127.0.0.1', help='MinKNOW server host.')
    p.add_argument('--port', type=int, default=8000, help='MinKNOW server port.')
    p.add_argument('--duration', type=float, default=None, help='Duration to map real-time run in hours. Should be slightly longer than specified runtime to add wiggle room.')

def add_list_ports_opts(p):
    p.add_argument('--log-dir', default='/var/log/MinKNOW', help='Directory to find MinKNOW log files')

def add_sim_opts(p):
    p.add_argument("--sim-speed", required=False, type=float, default=1, help="Speed of real-time simulation")
    p.add_argument("--sim-st", required=False, type=float, default=0, help="Reads that begin before this time will be filtered out")
    p.add_argument("--sim-en", required=False, type=float, default=0, help="Reads that begin after this time will be filtered out")
    p.add_argument("--sim-gaps", required=False, type=float, default=0.1, help="Extra gaps to add between reads")

def add_fast5_opts(p):
    p.add_argument("-i", "--fast5s", required=True, type=str, help="Reads to mapping. Can be a directory which will be recursively searched for all files with the \".fast5\" extension, a text file containing one fast5 filename per line, or a comma-separated list of fast5 file names.")
    p.add_argument("-f", "--filter", required=False, default="", type=str, help="Only map reads listed in this file")
    p.add_argument("-n", "--read-count", type=int, default=0, help="Maximum number of reads to map")

def add_map_opts(p):
    p.add_argument("-t", "--threads", default=1, type=int, help="Number of threads to use for mapping")
    p.add_argument("--num-channels", default=512, type=int, help="Number of channels used in sequencing. If provided will use unique mapper for each channel. Useful for streaming normalization simulation.")
    p.add_argument("-e", "--max-events-proc", default=30000, type=int, help="Will give up on a read after this many events have been processed")
    p.add_argument("--min-aln-len", default=25, type=int, help="Minimum number of basepairs a mapping must cover.")
    p.add_argument("--seed-len", default=22, type=int, help="Seed length in events.")
    p.add_argument("--min-rep-len", default=0, type=int, help="Minimum number of basepairs a multi-mapping seed must cover")
    p.add_argument("--max-rep-copy", default=50, type=int, help="Maximum number of locations for a multi-mapping seed")
    p.add_argument("--max-consec-stay", default=8, type=int, help="Maximum consecutive stay events.")
    p.add_argument("--max-paths", default=10000, type=int, help="Maximum number of paths to consider per event.")
    p.add_argument("--max-stay-frac", default=0.5, type=float, help="Expected fraction of events which are stays")
    p.add_argument("--min-seed-prob", default=-3.75, type=float, help="Average event probability threshold per seed")
    p.add_argument("--min-mean-conf", default=6.00, type=float, help="Minimum ratio between longest alignment and mean alignment length to report confident alignment")
    p.add_argument("--min-top-conf", default=1.85, type=float, help="Minimum ratio between longest alignment and second-longet alignment to report confident alignment")
    p.add_argument("--evt-min-mean", default=30, type=float, help="Minimum un-normalized event mean")
    p.add_argument("--evt-max-mean", default=150, type=float, help="Maximum un-normalized event mean")
    p.add_argument("--evt-window-length1", default=3, type=int, help="")
    p.add_argument("--evt-window-length2", default=6, type=int, help="")
    p.add_argument("--evt-threshold1", default=1.4, type=float, help="")
    p.add_argument("--evt-threshold2", default=9.0, type=float, help="")
    p.add_argument("--evt-peak-height", default=0.2, type=float, help="")

def get_parser():
    parser = argparse.ArgumentParser(description="Rapidly maps raw nanopore signal to DNA references")
    sp = parser.add_subparsers(dest="subcmd")

    index_parser = sp.add_parser("index", help="Calculates reference-specific parameters needed to map to a given a BWA-index.")#, formatter_class=ArgFormat)
    add_bwa_opt(index_parser)
    add_index_opts(index_parser)

    map_parser = sp.add_parser("map", help="Map fast5 files to a BWA index that has been processed by \"uncalled index\"")#,formatter_class=ArgFormat)
    add_bwa_opt(map_parser)
    add_fast5_opts(map_parser)
    add_map_opts(map_parser)

    rt_parser = sp.add_parser("realtime", help="Perform real-time targeted sequencing")#,formatter_class=ArgFormat)
    add_bwa_opt(rt_parser)
    add_map_opts(rt_parser)
    add_ru_opts(rt_parser)
    add_realtime_opts(rt_parser)

    ps_parser = sp.add_parser("pafstats", help="Computes speed and accuracy of UNCALLED mappings. Given an UNCALLED PAF file, will compute mean/median BP mapped per second, number of BP required to map each read, and total number of milliseconds to map each read. Can also optionally compute accuracy with respect to reference alignments, for example output by minimap2.")
    pafstats.add_opts(ps_parser)

    #Incomplete feature, currectly disabled
    #sim_parser = sp.add_parser("simulate", help="Simulate targeted sequencing based on previous run")#,formatter_class=ArgFormat)
    #add_bwa_opt(sim_parser)
    #add_map_opts(sim_parser)
    #add_ru_opts(sim_parser)
    #add_sim_opts(sim_parser)
    #add_fast5_opts(sim_parser)

    lp_parser = sp.add_parser("list-ports", help="List the port of all MinION devices detected in the current MinKNOW session")#,formatter_class=ArgFormat)
    add_list_ports_opts(lp_parser)

    return parser

def index_cmd(args):
    sys.stderr.write("Initializing parameter search\n")
    p = index.IndexParameterizer(args)

    p.add_preset("default", tgt_speed=115)

    if args.probs != None:
        for tgt in args.probs.split(","):
            sys.stderr.write("Writing 'prob_%s' parameters\n" % tgt)
            try:
                p.add_preset("prob_%s" % tgt, tgt_prob=float(tgt))
            except Exception as e:
                sys.stderr.write("Failed to add 'prob_%s'\n" % tgt)

    if args.speeds != None:
        for tgt in args.speeds.split(","):
            sys.stderr.write("Writing 'speed_%s' parameters\n" % tgt)
            try:
                p.add_preset("speed_%s" % tgt, tgt_speed=float(tgt))
            except:
                sys.stderr.write("Failed to add 'speed_%s'\n" % tgt)

    p.write()

    sys.stderr.write("Done\n")

def load_fast5s(arg):
    fast5s = list()
    if os.path.isdir(arg):
        for root, dirs, files in os.walk(arg):
            for fname in files:
                if not fname.startswith("#") and fname.endswith("fast5"):
                    fast5s.append(os.path.abspath(os.path.join(root, fname)))

    elif arg.endswith("fast5"):
        for fname in arg.split(","):
            fast5s.append(os.path.abspath(fname))

    else:
        fast5s = [os.path.abspath(l.strip()) for l in open(arg)]
    return fast5s

def assert_exists(fname):
    if not os.path.exists(fname):
        sys.stderr.write("Error: '%s' does not exist\n" % fname)
        sys.exit(1)

def map_cmd(args):

    assert_exists(index.MODEL_FNAME)
    assert_exists(args.bwa_prefix + ".bwt")
    assert_exists(args.bwa_prefix + ".uncl")
    assert_exists(args.fast5s)
    for fname in open(args.fast5s):
        assert_exists(fname.strip())
    if len(args.filter) > 0:
        assert_exists(args.filter)

    mapping.Params.init_map(args.bwa_prefix,
                        index.MODEL_FNAME,
                        args.preset_mode,
                        args.seed_len, 
                        args.min_aln_len,
                        args.min_rep_len, 
                        args.max_rep_copy, 
                        args.max_consec_stay,
                        args.max_paths, 
                        args.max_events_proc,
                        args.evt_window_length1,
                        args.evt_window_length2,
                        args.threads,
                        args.num_channels,
                        args.evt_threshold1,
                        args.evt_threshold2,
                        args.evt_peak_height,
                        args.evt_min_mean,
                        args.evt_max_mean,
                        args.max_stay_frac,
                        args.min_seed_prob, 
                        args.min_mean_conf,
                        args.min_top_conf);

    sys.stderr.write("Loading fast5s\n")

    mapper = mapping.Fast5Pool(args.fast5s, args.filter, args.read_count)
    sys.stderr.flush()

    sys.stderr.write("Mapping\n")

    n = 0

    try:
        while not mapper.all_finished() and (not args.read_count or n <= args.read_count):
            t0 = time.time()
            for p in mapper.update():
                p.print_paf()
                n += 1
                if args.read_count and n > args.read_count:
                    break
            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);
            #time.sleep(0.01)
    except KeyboardInterrupt:
        pass

    mapper.stop_all()
    while not mapper.all_finished():
        time.sleep(MAX_SLEEP)

    for p in mapper.update():
        p.print_paf()

def realtime_cmd(args):

    if not minknow_client.ru_loaded:
        sys.stderr.write("Error: read_until module not installed. Please install \"read_until_api\" submodule.\n")
        sys.exit(1)

    assert_exists(index.MODEL_FNAME)
    assert_exists(args.bwa_prefix + ".bwt")
    assert_exists(args.bwa_prefix + ".uncl")

    pool = None
    client = None

    try:
        client = minknow_client.Client(args.host, args.port, args.chunk_size)

        if not client.run():
            sys.exit(1)

        if (args.enrich and args.deplete) or not (args.enrich or args.deplete):
            sys.stderr.write("Must include exactly one of '--enrich' or '--deplete'\n")
            sys.exit(1)
        deplete = args.deplete

        cal = client.device.rpc.device.get_calibration(first_channel=1, last_channel=512)
        raw_type = str(client.signal_dtype)

        mapping.Params.init_realtime(args.bwa_prefix,
                            index.MODEL_FNAME,
                            args.preset_mode,
                            args.seed_len, 
                            args.min_aln_len,
                            args.min_rep_len, 
                            args.max_rep_copy, 
                            args.max_consec_stay,
                            args.max_paths, 
                            args.max_events_proc,
                            args.max_chunks_proc,
                            args.evt_buffer_len,
                            args.evt_window_length1,
                            args.evt_window_length2,
                            args.threads,
                            args.num_channels,
                            int(args.chunk_size*4000),
                            args.evt_batch_size,
                            args.evt_timeout,
                            args.evt_threshold1,
                            args.evt_threshold2,
                            args.evt_peak_height,
                            args.evt_min_mean,
                            args.evt_max_mean,
                            args.max_stay_frac,
                            args.min_seed_prob, 
                            args.min_mean_conf,
                            args.min_top_conf,
                            args.max_chunk_wait,
                            cal.digitisation,
                            cal.offsets,
                            cal.pa_ranges,
                            4000)

        pool = mapping.ChunkPool()

        chunk_times = [time.time() for c in range(args.num_channels)]
        unblocked = [None for c in range(args.num_channels)]

        client.log("Processing reads")

        if args.duration == None:
            end_time = float("inf")
        else:
            end_time = args.duration*60*60

        while client.is_running:
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if paf.is_ended():
                    paf.set_float(mapping.Paf.Tag.ENDED, t)
                    client.stop_receiving_read(ch, nm)

                elif (paf.is_mapped() and deplete) or not (paf.is_mapped() or deplete):

                    if client.should_eject():
                        paf.set_float(mapping.Paf.Tag.EJECT, t)
                        client.unblock_read(ch, nm)
                        unblocked[ch-1] = nm
                    else:
                        paf.set_float(mapping.Paf.Tag.IN_SCAN, t)
                        client.stop_receiving_read(ch, nm)

                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    client.stop_receiving_read(ch, nm)

                paf.print_paf()

            read_batch = client.get_read_chunks(batch_size=client.queue_length)

            for channel, read in read_batch:
                if args.even and channel % 2 == 1:
                    client.stop_receiving_read(channel, read.number)
                else:
                    if unblocked[channel-1] == read.number:
                        sys.stdout.write("# recieved chunk from %s after unblocking\n" % read.id)
                        continue

                    chunk_times[channel-1] = time.time()
                    pool.add_chunk(mapping.Chunk(read.id, 
                                                 channel, 
                                                 read.number,
                                                 read.chunk_start_sample,
                                                 raw_type,
                                                 read.raw_data))
                #last_time = time.time()

            if client.get_runtime() >= end_time:
                client.reset()
                client = None
                break

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);

    except KeyboardInterrupt:
        sys.stderr.write("Keyboard interrupt\n")

    except Exception as e:
        sys.stderr.write(traceback.format_exc())

    #client.log("Finished")

    if client != None:
        client.reset()

    if pool != None:
        pool.stop_all()



def simulate_cmd(args):
    if (args.enrich and args.deplete) or not (args.enrich or args.deplete):
        sys.stderr.write("Must include exactly one of '--enrich' or '--deplete'\n")
        sys.exit(1)
    deplete = args.deplete

    sys.stdout.flush()
    opts = mapping.Params.init_sim(args.bwa_prefix,
                        index.MODEL_FNAME,
                        args.preset_mode,
                        args.seed_len, 
                        args.min_aln_len,
                        args.min_rep_len, 
                        args.max_rep_copy, 
                        args.max_consec_stay,
                        args.max_paths, 
                        args.max_events_proc,
                        args.max_chunks_proc,
                        args.evt_buffer_len,
                        args.evt_window_length1,
                        args.evt_window_length2,
                        args.threads,
                        args.num_channels,
                        int(args.chunk_size*4000),
                        args.evt_batch_size,
                        args.evt_timeout,
                        args.evt_threshold1,
                        args.evt_threshold2,
                        args.evt_peak_height,
                        args.evt_min_mean,
                        args.evt_max_mean,
                        args.max_stay_frac,
                        args.min_seed_prob, 
                        args.min_mean_conf,
                        args.min_top_conf,
                        args.max_chunk_wait,
                        args.sim_speed,
                        args.sim_st,
                        args.sim_en,
                        args.sim_gaps,
                        args.even,
                        args.odd)

    sys.stderr.write("Loading simulator\n")
    sys.stderr.flush()
    #TODO: pass opts, not individual params
    sim = mapping.Simulator()
    sim.add_fast5s(args.fast5s, args.read_count)
    pool = mapping.ChunkPool()

    sys.stderr.write("Mapping\n")
    sys.stderr.flush()


    chunk_times = [time.time() for c in range(args.num_channels)]

    if args.even == args.odd:
        monitor_ch = [True for c in range(args.num_channels)]
    elif args.even:
        monitor_ch = [c % 2 == 1 for c in range(args.num_channels)]
    elif args.odd:
        monitor_ch = [c % 2 == 0 for c in range(args.num_channels)]
        
    try:
        sim.start()
        while sim.is_running() or not pool.all_finished():
            sys.stderr.flush()
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if not paf.is_ended() and ((paf.is_mapped() and deplete) 
                                           or not (paf.is_mapped() or deplete)):
                    paf.set_float(mapping.Paf.Tag.EJECT, t)
                    sim.unblock(ch, nm)
                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    sim.stop_receiving_read(ch, nm)
                paf.print_paf()

            
            for chunk in sim.get_read_chunks():
                #sys.stderr.write("# chunk %d\n" % chunk.get_channel())
                if monitor_ch[chunk.get_channel()-1]:
                    chunk_times[chunk.get_channel()-1] = time.time()
                    pool.add_chunk(chunk)
                else:
                    sim.stop_receiving_read(chunk.get_channel(), chunk.get_number())

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);
    except KeyboardInterrupt:
        pass

    if pool != None:
        pool.stop_all()

def list_ports_cmd(args):
    log_re = re.compile("^([0-9\-]+ [0-9:]+).+ :.+instance_started.+")
    port_re = re.compile("grpc_port = (\d+)")
    device_re = re.compile("(device_id|instance) = ([^\s,]+)")

    fnames = os.listdir(args.log_dir)
    log_fnames = list(sorted( (f for f in fnames if f.startswith("mk_manager_svc")) ))
    latest_log = os.path.join(args.log_dir, log_fnames[-1])

    for line in open(latest_log):
        lm = log_re.match(line)
        if not lm: continue
        pm = port_re.search(line)
        dm = device_re.search(line)

        if pm is None or dm is None:
            sys.stderr.write("Error: failed to parse \"%s\"\n" % line.strip())
            continue

        timestamp = lm.group(1)
        port = pm.group(1)
        device = dm.group(2)

        sys.stdout.write("%s (%s): %s\n" % (device, timestamp, port))



if __name__ == "__main__":
    
    parser = get_parser()
    args = parser.parse_args()

    if args.subcmd == "index":
        index_cmd(args)
    elif args.subcmd == "map":
        map_cmd(args)
    elif args.subcmd == "realtime":
        realtime_cmd(args)
    elif args.subcmd == "list-ports":
        list_ports_cmd(args)
    elif args.subcmd == "pafstats":
        pafstats.run(args)
    #Incomplete feature, currently disabled
    #elif args.subcmd == "simulate":
    #    simulate_cmd(args)
    else:
        parser.print_help()
        
