#!/usr/bin/env python

# MIT License
#
# Copyright (c) 2018 Sam Kovaka <skovaka@gmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

from uncalled import mapping, index
import sys                         
import os
import argparse
import time
import re
import time

class ArgFormat(argparse.ArgumentDefaultsHelpFormatter):
                #argparse.MetavarTypeHelpFormatter):
    pass

def add_bwa_opt(p):
    p.add_argument("-x", "--bwa-prefix", required=True, type=str, help="BWA prefix to mapping to. Must be processed by \"uncalled index\".")

def add_index_opts(p):
    p.add_argument("-i", "--ref-fasta", required=True, type=str, help="FASTA file used to build BWA index")
    p.add_argument("-s", "--sample-dist", default=1000, type=int, help="Sampling distance between reference self-alignments. Reduce number for larger genomes.")
    p.add_argument("-k", "--kmer-len", default=5, type=int, help="Model k-mer length")
    p.add_argument("-1", "--matchpr1", default=0.6225, type=float, help="Minimum event match probability")
    p.add_argument("-2", "--matchpr2", default=0.9837, type=float, help="Maximum event match probability")
    p.add_argument("-p", "--match-prod", default=0.05, type=float, help="Target frequency of seeds.")
    p.add_argument("-f", "--fm-percentile", default=95, type=int, help=" ")

def add_ru_opts(p):
    #TODO: selectively enrich or deplete refs in index
    p.add_argument("--deplete", required=False, action='store_true', default=False, help="Will eject reads that align to index")
    p.add_argument("--enrich", required=False, action='store_true', default=False, help="Will eject reads that don't align to index")
    p.add_argument("--even", action='store_true', help="Will only monitor even pores if set")
    p.add_argument("--chunk-len", required=False, type=int, default=4000, help="Length of chunks")
    p.add_argument("-n", "--evt-buffer-len", default=6000, type=int, help="Size of buffer used to normalize and read events")
    p.add_argument("-E", "--evt-batch-size", default=5, type=int, help="Number of events simulator will mapping per read per thread iteration. Only has effect when --unblock is set")
    p.add_argument("--evt-timeout", default=10.0, type=float, help="Simulator will stop aligning event batch if average time in MS to mapping an event exceeds this. Only has effect when --unblock is set")
    p.add_argument("-c", "--max-chunks-proc", default=3, type=int, help="Will give up on a read after this many chunks have been processed. Only has effect when --unblock is set")
    p.add_argument("--max-chunk-wait", required=False, type=float, default=4000, help="Maximum milliseconds to wait between chunks. Will give up on read if it takes longer")

def add_realtime_opts(p):
    p.add_argument('--host', default='127.0.0.1', help='MinKNOW server host.')
    p.add_argument('--port', type=int, default=8000, help='MinKNOW server port.')

def add_sim_opts(p):
    p.add_argument("--sim-speed", required=False, type=float, default=1, help="Speed of real-time simulation")
    p.add_argument("--sim-st", required=False, type=float, default=0, help="Reads that begin before this time will be filtered out")
    p.add_argument("--sim-en", required=False, type=float, default=0, help="Reads that begin after this time will be filtered out")

def add_fast5_opts(p):
    p.add_argument("-i", "--fast5s", required=True, type=str, help="Reads to mapping. Can be a directory which will be recursively searched for all files with the \".fast5\" extension, a text file containing one fast5 filename per line, or a comma-separated list of fast5 file names.")
    p.add_argument("-R", "--read-count", type=int, default=0, help="Maximum number of reads to map")

def add_map_opts(p):
    p.add_argument("-C", "--num-channels", default=512, type=int, help="Number of channels used in sequencing. If provided will use unique mapper for each channel. Useful for streaming normalization simulation.")
    p.add_argument("-t", "--threads", default=1, type=int, help="Number of threads to use for mapping")
    p.add_argument("-e", "--max-events-proc", default=30000, type=int, help="Will give up on a read after this many events have been processed")
    p.add_argument("-a", "--min-aln-len", default=25, type=int, help="Minimum number of basepairs a mapping must cover.")
    p.add_argument("-s", "--seed-len", default=22, type=int, help="Seed length in events.")
    p.add_argument("-r", "--min-rep-len", default=0, type=int, help="Minimum number of basepairs a multi-mapping seed must cover")
    p.add_argument("--max-rep-copy", default=50, type=int, help="Maximum number of locations for a multi-mapping seed")
    p.add_argument("-y", "--max-consec-stay", default=8, type=int, help="Maximum consecutive stay events.")
    p.add_argument("-p", "--max-paths", default=10000, type=int, help="Maximum number of paths to consider per event.")
    p.add_argument("-F", "--max-stay-frac", default=0.5, type=float, help="Expected fraction of events which are stays")
    p.add_argument("-S", "--min-seed-prob", default=-3.75, type=float, help="Average event probability threshold per seed")
    p.add_argument("-M", "--min-mean-conf", default=7.00, type=float, help="Minimum ratio between longest alignment and mean alignment length to report confident alignment")
    p.add_argument("-T", "--min-top-conf", default=2.25, type=float, help="Minimum ratio between longest alignment and second-longet alignment to report confident alignment")
    p.add_argument("--evt-min-mean", default=30, type=float, help="Minimum un-normalized event mean")
    p.add_argument("--evt-max-mean", default=150, type=float, help="Maximum un-normalized event mean")
    p.add_argument("--evt-window-length1", default=3, type=int, help=" ")
    p.add_argument("--evt-window-length2", default=6, type=int, help=" ")
    p.add_argument("--evt-threshold1", default=1.4, type=float, help=" ")
    p.add_argument("--evt-threshold2", default=9.0, type=float, help=" ")
    p.add_argument("--evt-peak-height", default=0.2, type=float, help=" ")

def get_parser():
    parser = argparse.ArgumentParser(description="Rapidly maps raw nanopore signal to DNA references")
    sp = parser.add_subparsers(dest="subcmd")

    index_parser = sp.add_parser("index", help="Calculates reference-specific parameters needed to map to a given a BWA-index.")#, formatter_class=ArgFormat)
    add_bwa_opt(index_parser)
    add_index_opts(index_parser)

    map_parser = sp.add_parser("map", help="Map fast5 files to a BWA index that has been processed by \"uncalled index\"")#,formatter_class=ArgFormat)
    add_bwa_opt(map_parser)
    add_map_opts(map_parser)
    add_fast5_opts(map_parser)

    rt_parser = sp.add_parser("realtime", help="Perform real-time targeted sequencing")#,formatter_class=ArgFormat)
    add_bwa_opt(rt_parser)
    add_map_opts(rt_parser)
    add_ru_opts(rt_parser)
    add_realtime_opts(rt_parser)

    sim_parser = sp.add_parser("simulate", help="Simulate targeted sequencing based on previous run")#,formatter_class=ArgFormat)
    add_bwa_opt(sim_parser)
    add_map_opts(sim_parser)
    add_ru_opts(sim_parser)
    add_sim_opts(sim_parser)
    add_fast5_opts(sim_parser)

    return parser

def load_fast5s(arg):
    fast5s = list()
    if os.path.isdir(arg):
        for root, dirs, files in os.walk(arg):
            for fname in files:
                if not fname.startswith("#") and fname.endswith("fast5"):
                    fast5s.append(os.path.abspath(os.path.join(root, fname)))

    elif arg.endswith("fast5"):
        for fname in arg.split(","):
            fast5s.append(os.path.abspath(fname))

    else:
        fast5s = [os.path.abspath(l.strip()) for l in open(arg)]
    return fast5s

def index_cmd(args):
    fmlens = mapping.self_align(args.bwa_prefix, args.ref_fasta, args.sample_dist)

    index.get_params(args.bwa_prefix, 
                     fmlens, 
                     args.kmer_len, 
                     args.fm_percentile, 
                     args.matchpr1, 
                     args.matchpr2, 
                     args.match_prod)

def map_cmd(args):
    sys.stderr.write("Regular mapping is currently disabled due to refactoring and a deadline\n")

def map_cmd_old(args):
    mapping.Params.init_map(args.bwa_prefix,
                        index.MODEL_FNAME,
                        args.seed_len, 
                        args.min_aln_len,
                        args.min_rep_len, 
                        args.max_rep_copy, 
                        args.max_consec_stay,
                        args.max_paths, 
                        args.max_events_proc,
                        args.evt_window_length1,
                        args.evt_window_length2,
                        args.threads,
                        args.evt_threshold1,
                        args.evt_threshold2,
                        args.evt_peak_height,
                        args.evt_min_mean,
                        args.evt_max_mean,
                        args.max_stay_frac,
                        args.min_seed_prob, 
                        args.min_mean_conf,
                        args.min_top_conf);

    sys.stderr.write("Reading fast5 paths\n")
    fast5s = load_fast5s(args.fast5s)

    if args.threads == 1:
        sys.stderr.write("Aligning\n")
        mapper = mapping.Mapper(opts)

        try:
            for fast5 in fast5s:
                print(mapper.map_fast5(fast5))
                sys.stdout.flush()

        except KeyboardInterrupt:
            pass

    else:
        mapper = mapping.Fast5Pool(opts)
        mapper.add_fast5s(fast5s)

        sys.stderr.write("Aligning\n")
        sys.stderr.flush()

        try:
            while not mapper.all_finished():
                alns = mapper.update()
                for a in alns:
                    sys.stdout.write("%s\n" % a)
                sys.stdout.flush()
                time.sleep(0.01)
        except KeyboardInterrupt:
            pass

        sys.stderr.write("Waiting for threads to finish...\n")
        mapper.stop_all()

def realtime_cmd(args):
    import read_until
    try:

        client = read_until.ReadUntilClient(mk_host=args.host, 
                                            mk_port=args.port, 
                                            one_chunk=False, 
                                            filter_strands=True,
                                            prefilter_classes={'strand', 'strand1', 'strand2'})
        client.run()

        if (args.enrich and args.deplete) or not (args.enrich or args.deplete):
            sys.stderr.write("Must include exactly one of '--enrich' or '--deplete'\n")
            sys.exit(1)
        deplete = args.deplete

        cal = client.device.rpc.device.get_calibration(first_channel=1, last_channel=512)
        raw_type = str(client.signal_dtype)

        mapping.Params.init_realtime(args.bwa_prefix,
                            index.MODEL_FNAME,
                            args.seed_len, 
                            args.min_aln_len,
                            args.min_rep_len, 
                            args.max_rep_copy, 
                            args.max_consec_stay,
                            args.max_paths, 
                            args.max_events_proc,
                            args.max_chunks_proc,
                            args.evt_buffer_len,
                            args.evt_window_length1,
                            args.evt_window_length2,
                            args.threads,
                            args.num_channels,
                            args.chunk_len,
                            args.evt_batch_size,
                            args.evt_timeout,
                            args.evt_threshold1,
                            args.evt_threshold2,
                            args.evt_peak_height,
                            args.evt_min_mean,
                            args.evt_max_mean,
                            args.max_stay_frac,
                            args.min_seed_prob, 
                            args.min_mean_conf,
                            args.min_top_conf,
                            args.max_chunk_wait,
                            cal.digitisation,
                            cal.offsets,
                            cal.pa_ranges,
                            4000)

        pool = mapping.ChunkPool()

        chunk_times = [time.time() for c in range(args.num_channels)]

        sys.stderr.write("Mapping\n")
        
        MAX_SLEEP = 0.01
        
        while client.is_running:
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if (paf.is_mapped() and deplete) or not (paf.is_mapped() or deplete):
                    paf.set_float(mapping.Paf.Tag.UNBLOCK, t)
                    client.unblock_read(ch, nm)
                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    client.stop_receiving_read(ch, nm)  
                paf.print_paf()
                sys.stdout.flush()
            
            if client.queue_length == 0:
                dt = time.time() - t0;
                if dt < MAX_SLEEP:
                    time.sleep(MAX_SLEEP - dt);
                continue

            read_batch = client.get_read_chunks(batch_size=client.queue_length)

            for channel, read in read_batch:
                if args.even and channel % 2 == 1:
                    client.stop_receiving_read(channel, read.number)
                else:
                    chunk_times[channel-1] = time.time()
                    pool.add_chunk(mapping.Chunk(read.id, 
                                                 channel, 
                                                 read.number,
                                                 read.chunk_start_sample,
                                                 raw_type,
                                                 read.raw_data))

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);

    except Exception as e:
        sys.stderr.write("Error: %s\n" % str(e))
        pass

    pool.stop_all();
    client.reset()


def simulate_cmd(args):
    if (args.enrich and args.deplete) or not (args.enrich or args.deplete):
        sys.stderr.write("Must include exactly one of '--enrich' or '--deplete'\n")
        sys.exit(1)
    deplete = args.deplete

    sys.stdout.flush()
    opts = mapping.Params.init_sim(args.bwa_prefix,
                        index.MODEL_FNAME,
                        args.seed_len, 
                        args.min_aln_len,
                        args.min_rep_len, 
                        args.max_rep_copy, 
                        args.max_consec_stay,
                        args.max_paths, 
                        args.max_events_proc,
                        args.max_chunks_proc,
                        args.evt_buffer_len,
                        args.evt_window_length1,
                        args.evt_window_length2,
                        args.threads,
                        args.num_channels,
                        args.chunk_len,
                        args.evt_batch_size,
                        args.evt_timeout,
                        args.evt_threshold1,
                        args.evt_threshold2,
                        args.evt_peak_height,
                        args.evt_min_mean,
                        args.evt_max_mean,
                        args.max_stay_frac,
                        args.min_seed_prob, 
                        args.min_mean_conf,
                        args.min_top_conf,
                        args.max_chunk_wait,
                        args.sim_speed,
                        args.sim_st,
                        args.sim_en,
                        args.even);

    sys.stderr.write("Loading simulator\n")
    sys.stderr.flush()
    #TODO: pass opts, not individual params
    sim = mapping.Simulator()
    sim.add_fast5s(args.fast5s, args.read_count)
    pool = mapping.ChunkPool()

    sys.stderr.write("Mapping\n")
    sys.stderr.flush()

    MAX_SLEEP = 0.01

    chunk_times = [time.time() for c in range(args.num_channels)]
        
    try:
        sim.start()
        while sim.is_running() or not pool.all_finished():
            sys.stderr.flush()
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if (paf.is_mapped() and deplete) or not (paf.is_mapped() or deplete):
                    paf.set_float(mapping.Paf.Tag.UNBLOCK, t)
                    sim.unblock(ch, nm)
                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    sim.stop_receiving_read(ch, nm)
                paf.print_paf()

            
            for chunk in sim.get_read_chunks():
                if args.even and chunk.get_channel() % 2 == 1:
                    sim.stop_receiving_read(chunk.get_channel(), chunk.get_number())
                else:
                    chunk_times[chunk.get_channel()-1] = time.time()
                    pool.add_chunk(chunk)

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);
    except KeyboardInterrupt:
        pass

    pool.stop_all();


if __name__ == "__main__":
    
    parser = get_parser()
    args = parser.parse_args()

    if args.subcmd == "index":
        index_cmd(args)
    elif args.subcmd == "map":
        map_cmd(args)
    elif args.subcmd == "realtime":
        realtime_cmd(args)
    elif args.subcmd == "simulate":
        simulate_cmd(args)
    else:
        parser.print_help()
        
